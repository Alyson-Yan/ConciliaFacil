{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import numpy as np\n",
    "from rapidfuzz import process, fuzz\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================\n",
    "# Configuração do sistema de logs\n",
    "#================================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('conciliacao_erros.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def resource_path(relative_path):\n",
    "    \n",
    "    try:\n",
    "        base_path = sys._MEIPASS\n",
    "    except Exception:\n",
    "        base_path = os.path.abspath(\".\")\n",
    "    return os.path.join(base_path, relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================\n",
    "# === FUNÇÕES: CARREGAMENTO DE PLANILHAS ===\n",
    "#===========================================\n",
    "\n",
    "def carregar_planilha(caminho):\n",
    "    try:\n",
    "        logging.info(f\"Tentando carregar planilha: {getattr(caminho, 'name', caminho)}\")\n",
    "        if caminho.name.endswith(\".csv\"):\n",
    "            df = pd.read_csv(\n",
    "                caminho, \n",
    "                sep=\";\", \n",
    "                encoding=\"latin1\", \n",
    "                dtype={\n",
    "                    \"NSU\": str,\n",
    "                    \"NSU Concentrador\": str\n",
    "                }\n",
    "            )\n",
    "            logging.info(f\"Planilha CSV carregada com sucesso: {df.shape}\")\n",
    "            return df\n",
    "        else:\n",
    "            df = pd.read_excel(caminho, dtype={\"NSU/DOC\": str})\n",
    "            logging.info(f\"Planilha Excel carregada com sucesso: {df.shape}\")\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao carregar arquivo {getattr(caminho, 'name', caminho)}: {str(e)}\", exc_info=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================\n",
    "# =========== FORMATAÇÂO CIELO ===============\n",
    "#=============================================\n",
    "\n",
    "def limpar_cielo(df):\n",
    "    try:\n",
    "        logging.debug(\"Iniciando limpeza da planilha Cielo\")\n",
    "        # Remove cabeçalhos e linhas inválidas\n",
    "        df = df.iloc[8:].reset_index(drop=True)\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df[1:].reset_index(drop=True)\n",
    "        df.dropna(axis='columns', how='all', inplace=True)\n",
    "        \n",
    "        # Normalizar nomes das colunas (minúsculas e sem espaços)\n",
    "        df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "        # Selecionar e garantir colunas necessárias\n",
    "        colunas_cielo = [\n",
    "            \"data de pagamento\",\n",
    "            \"data do lançamento\",\n",
    "            \"estabelecimento\",\n",
    "            \"tipo de lançamento\",\n",
    "            \"bandeira\",\n",
    "            \"valor bruto\",\n",
    "            \"taxa/tarifa\",\n",
    "            \"valor líquido\",\n",
    "            \"data da venda\",\n",
    "            \"data prevista de pagamento\",\n",
    "            \"código da autorização\",\n",
    "            \"nsu/doc\",\n",
    "            \"número da parcela\",\n",
    "            \"quantidade total de parcelas\",\n",
    "            \"valor total da transação\",\n",
    "        ]\n",
    "\n",
    "        # Verificar colunas faltantes\n",
    "        colunas_faltantes = set([col.lower() for col in colunas_cielo]) - set(df.columns)\n",
    "        if colunas_faltantes:\n",
    "            raise ValueError(f\"Colunas faltantes: {colunas_faltantes}\")\n",
    "        df = df[[col.lower() for col in colunas_cielo]]\n",
    "\n",
    "        # Converter valores numéricos (tratamento robusto)\n",
    "        # Converter valores numéricos (mantendo padrão em reais)\n",
    "        for col in [\"valor bruto\", \"taxa/tarifa\", \"valor líquido\", \"valor total da transação\"]:\n",
    "            df[col] = (\n",
    "                df[col].astype(str)\n",
    "                    .str.replace(',', '.', regex=False)      # Converte vírgula decimal\n",
    "                    .astype(float)\n",
    "            )\n",
    "\n",
    "\n",
    "        # Converter datas com tratamento de erros\n",
    "        for col in [\"data de pagamento\", \"data do lançamento\", \"data da venda\", \"data prevista de pagamento\"]:\n",
    "            df[col] = pd.to_datetime(df[col], dayfirst=True, errors='coerce')\n",
    "            nat_count = df[col].isna().sum()\n",
    "            if nat_count > 0:\n",
    "                logging.warning(f\"{nat_count} datas inválidas na coluna {col}\")\n",
    "\n",
    "        # Colunas para inteiro\n",
    "        for col in [\"número da parcela\", \"quantidade total de parcelas\"]:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "        # Renomear colunas\n",
    "        df = df.rename(columns={\n",
    "            \"valor bruto\": \"VALOR DA PARCELA\",\n",
    "            \"valor líquido\": \"VALOR LÍQUIDO\",\n",
    "            \"número da parcela\": \"PARCELA\",\n",
    "            \"quantidade total de parcelas\": \"TOTAL_PARCELAS\",\n",
    "            \"código da autorização\": \"AUTORIZAÇÃO\",\n",
    "            \"nsu/doc\": \"NSU/DOC\",\n",
    "            \"data da venda\": \"DATA DA VENDA\",\n",
    "            \"data prevista de pagamento\": \"DATA DE VENCIMENTO\",\n",
    "            \"bandeira\": \"BANDEIRA / MODALIDADE\",\n",
    "            \"tipo de lançamento\": \"Tipo de lançamento\"\n",
    "        })\n",
    "\n",
    "\n",
    "        logging.info(\"Limpeza da planilha Cielo concluída com sucesso\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro crítico em limpar_cielo: {str(e)}\", exc_info=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================\n",
    "# =========== FORMATAÇÂO ERP =================\n",
    "#=============================================\n",
    "\n",
    "\n",
    "def limpar_erp(df):\n",
    "    try:\n",
    "        logging.debug(\"Iniciando limpeza da planilha ERP\")\n",
    "        # Remover colunas irrelevantes\n",
    "        cols_to_drop = [\"Nome do Cliente\", \"Tipo\", \"Carteira\", \"Caracterização da Venda\", \"1o. Agrupamento\"]\n",
    "        for col in cols_to_drop:\n",
    "            if col in df.columns:\n",
    "                df.drop(columns=[col], inplace=True)\n",
    "        # Converter coluna 'Emissão' para data\n",
    "        df[\"Emissão\"] = pd.to_datetime(df[\"Emissão\"], dayfirst=True, errors=\"coerce\")\n",
    "        # Extrair 'Numero da Parcela' e 'Total Parcelas' da coluna 'Numero' (formato 'id-X/Y')\n",
    "        parcela_info = df[\"Numero\"].str.extract(r'-(\\d+)/(\\d+)')\n",
    "        df[\"Numero da Parcela\"] = parcela_info[0].astype(int)\n",
    "        df[\"Total Parcelas\"]    = parcela_info[1].astype(int)\n",
    "        # Formatação numérica de valores\n",
    "        # Formatação numérica de valores (mantendo padrão em reais)\n",
    "        for col in [\"Valor\", \"Vr Corrigido\", \"Taxa\"]:\n",
    "            df[col] = (\n",
    "            df[col].astype(str)\n",
    "                .str.replace(',', '.', regex=False)     # Converte vírgula decimal\n",
    "                .astype(float)\n",
    "        )\n",
    "\n",
    "        logging.info(\"Limpeza da planilha ERP concluída com sucesso\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao preparar dados ERP: {str(e)}\", exc_info=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================\n",
    "# === FUNÇÃO PRINCIPAL: CONCILIADOR ==========\n",
    "#=============================================\n",
    "\n",
    "\n",
    "# === FUNÇÕES: CONCILIAÇÃO POR PONTUAÇÃO ===\n",
    "\n",
    "# -- (Regiel) Aqui temos várias funções dentro de uma função!!! \n",
    "def selecionar_melhor_por_pontuacao(row, df_erp_base, tolerancia_dias=3, tolerancia_valor=0.20, incluir_detalhes=False):\n",
    "    try:\n",
    "        logging.debug(f\"[MATCH] Iniciando para linha: {row.to_dict()}\")\n",
    "\n",
    "        # --- NOVO: checar NSU e Autorização 100% iguais --- Cria um dataframe match onde autorização do erp = nsu cielo e nsu erp = nsu cielo\n",
    "        nsu_cielo = str(row[\"NSU/DOC\"])\n",
    "        aut_cielo = str(row[\"AUTORIZAÇÃO\"])\n",
    "        match = df_erp_base[\n",
    "            (df_erp_base[\"NSU\"].astype(str) == nsu_cielo) &\n",
    "            (df_erp_base[\"Autorização\"].astype(str) == aut_cielo)\n",
    "        ]\n",
    "        # -- Caso tenha a df match não seja vazia ele completa o df com mais duas colunas com valores Conciliado e 0 (sistema de pontuação onde 0 é a conciliação perfeita)\n",
    "        # -- (Regiel) Pra mim antes de validar o NSU e autorização precisariamos validar data da venda, valor da venda, parcela e total de parcelas antes de dizer que o df match está conciliado\n",
    "        if not match.empty:\n",
    "            linha = match.iloc[0]\n",
    "            return pd.Series([linha[\"Autorização\"], linha[\"NSU\"], linha[\"Chave\"], linha[\"Valor\"], \"Conciliado\", 0])\n",
    "\n",
    "        # --- Lógica existente ---\n",
    "        mask = (\n",
    "            (abs((df_erp_base[\"Emissão\"] - row[\"DATA DA VENDA\"]).dt.days) <= tolerancia_dias) &\n",
    "            (abs(df_erp_base[\"Valor\"] - row[\"VALOR DA PARCELA\"]) <= tolerancia_valor) &\n",
    "            (df_erp_base[\"Numero da Parcela\"] == row[\"PARCELA\"]) &\n",
    "            (df_erp_base[\"Total Parcelas\"] == row[\"TOTAL_PARCELAS\"])\n",
    "        )\n",
    "        candidatos = df_erp_base[mask]\n",
    "\n",
    "        melhor_resultado = None\n",
    "        menor_pontuacao = float(\"inf\")\n",
    "\n",
    "        for _, linha in candidatos.iterrows():\n",
    "            dias_dif = abs((linha[\"Emissão\"] - row[\"DATA DA VENDA\"]).days)\n",
    "            valor_dif = abs(linha[\"Valor\"] - row[\"VALOR DA PARCELA\"])\n",
    "            sim_autorizacao = fuzz.ratio(aut_cielo, linha[\"Autorização\"])\n",
    "            sim_nsu = fuzz.ratio(nsu_cielo, linha[\"NSU\"])\n",
    "            pontuacao = dias_dif * 10 + valor_dif * 100 + (100 - sim_nsu) + (100 - sim_autorizacao)\n",
    "            status = []\n",
    "            if dias_dif > tolerancia_dias:\n",
    "                status.append(\"Divergência de Data\")\n",
    "            if valor_dif > tolerancia_valor:\n",
    "                status.append(\"Divergência de Valor\")\n",
    "            if row[\"PARCELA\"] != linha[\"Numero da Parcela\"]:\n",
    "                status.append(\"Divergência de Parcela\")\n",
    "            if row[\"TOTAL_PARCELAS\"] != linha[\"Total Parcelas\"]:\n",
    "                status.append(\"Divergência de Total de Parcelas\")\n",
    "            status_final = \" e \".join(status) if status else \"Conciliado\"\n",
    "            if pontuacao < menor_pontuacao:\n",
    "                menor_pontuacao = pontuacao\n",
    "                melhor_resultado = (\n",
    "                    linha[\"Autorização\"], linha[\"NSU\"], linha[\"Chave\"], linha[\"Valor\"], status_final, round(pontuacao, 0)\n",
    "                )\n",
    "\n",
    "        return pd.Series(melhor_resultado) if melhor_resultado else pd.Series([None, None, None, None, \"Não Conciliado\", 999])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro em selecionar_melhor_por_pontuacao: {str(e)}\", exc_info=True)\n",
    "        return pd.Series([None, None, None, None, \"Erro na Conciliação\", 999])\n",
    "\n",
    "\n",
    "\n",
    "def conciliar_por_nsu(row, df_erp_base, tolerancia_dias=1, tolerancia_valor=0.15):\n",
    "    try:\n",
    "        logging.debug(f\"[NSU] Tentando conciliar por NSU: {row['NSU/DOC']}\")\n",
    "\n",
    "        nsu_cielo = str(row['NSU/DOC'])\n",
    "        aut_cielo = str(row['AUTORIZAÇÃO'])\n",
    "\n",
    "        # --- NOVO: checar NSU e Autorização 100% iguais ---\n",
    "        match = df_erp_base[\n",
    "            (df_erp_base[\"NSU\"].astype(str) == nsu_cielo) &\n",
    "            (df_erp_base[\"Autorização\"].astype(str) == aut_cielo)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            linha = match.iloc[0]\n",
    "            return pd.Series([linha[\"Autorização\"], linha[\"NSU\"], linha[\"Chave\"], linha[\"Valor\"], \"Conciliado\", 0])\n",
    "\n",
    "        # --- Busca fuzzy original ---\n",
    "        nsus_erp = df_erp_base['NSU'].astype(str)\n",
    "        correspondencias = process.extract(nsu_cielo, nsus_erp, scorer=fuzz.ratio, limit=5)\n",
    "\n",
    "        correspondencias_validas = [(texto, score, idx) for texto, score, idx in correspondencias if score >= 80]\n",
    "        if not correspondencias_validas:\n",
    "            return pd.Series([None, None, None, None, \"Não Conciliado\", 999])\n",
    "\n",
    "        melhor_resultado = None\n",
    "        menor_pontuacao = float(\"inf\")\n",
    "\n",
    "        for _, score, idx in correspondencias_validas:\n",
    "            linha = df_erp_base.iloc[idx]\n",
    "            dias_dif = abs((linha[\"Emissão\"] - row[\"DATA DA VENDA\"]).days)\n",
    "            valor_dif = abs(linha[\"Valor\"] - row[\"VALOR DA PARCELA\"])\n",
    "            pontuacao = dias_dif * 10 + valor_dif * 100 + (100 - score)\n",
    "            status = []\n",
    "            if dias_dif > 1:\n",
    "                status.append(\"Divergência de Data\")\n",
    "            if valor_dif > 0.10:\n",
    "                status.append(\"Divergência de Valor\")\n",
    "            status_final = \" e \".join(status) if status else \"Conciliado\"\n",
    "            if pontuacao < menor_pontuacao:\n",
    "                menor_pontuacao = pontuacao\n",
    "                melhor_resultado = (\n",
    "                    linha[\"Autorização\"], linha[\"NSU\"], linha[\"Chave\"], linha[\"Valor\"], status_final, round(pontuacao, 2)\n",
    "                )\n",
    "\n",
    "        return pd.Series(melhor_resultado)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro em conciliar_por_nsu: {str(e)}\", exc_info=True)\n",
    "        return pd.Series([None, None, None, None, \"Erro na Conciliação NSU\", 999])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def conciliar_por_autorizacao(row, df_erp_base, tolerancia_dias=2, tolerancia_valor=0.30):\n",
    "    try:\n",
    "        aut_cielo = str(row['AUTORIZAÇÃO'])\n",
    "        nsu_cielo = str(row['NSU/DOC'])\n",
    "\n",
    "        # --- NOVO: checar NSU e Autorização 100% iguais ---\n",
    "        match = df_erp_base[\n",
    "            (df_erp_base[\"Autorização\"].astype(str) == aut_cielo) &\n",
    "            (df_erp_base[\"NSU\"].astype(str) == nsu_cielo)\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            linha = match.iloc[0]\n",
    "            return pd.Series([linha[\"Autorização\"], linha[\"NSU\"], linha[\"Chave\"], linha[\"Valor\"], \"Conciliado\", 0])\n",
    "\n",
    "        # --- Busca fuzzy original ---\n",
    "        autorizacoes_erp = df_erp_base['Autorização'].astype(str)\n",
    "        correspondencias = process.extract(aut_cielo, autorizacoes_erp, scorer=fuzz.ratio, limit=5)\n",
    "\n",
    "        correspondencias_validas = [(texto, score, idx) for texto, score, idx in correspondencias if score >= 80]\n",
    "        if not correspondencias_validas:\n",
    "            return pd.Series([None, None, None, None, \"Não Conciliado\", 999])\n",
    "\n",
    "        melhor_resultado = None\n",
    "        menor_pontuacao = float(\"inf\")\n",
    "\n",
    "        for _, score, idx in correspondencias_validas:\n",
    "            linha = df_erp_base.iloc[idx]\n",
    "            dias_dif = abs((linha[\"Emissão\"] - row[\"DATA DA VENDA\"]).days)\n",
    "            valor_dif = abs(linha[\"Valor\"] - row[\"VALOR DA PARCELA\"])\n",
    "            pontuacao = dias_dif * 10 + valor_dif * 100 + (100 - score)\n",
    "            status = []\n",
    "            if dias_dif > tolerancia_dias:\n",
    "                status.append(\"Divergência de Data\")\n",
    "            if valor_dif > tolerancia_valor:\n",
    "                status.append(\"Divergência de Valor\")\n",
    "            status_final = \" | \".join(status) if status else \"Conciliado por Autorização\"\n",
    "            if pontuacao < menor_pontuacao:\n",
    "                menor_pontuacao = pontuacao\n",
    "                melhor_resultado = (\n",
    "                    linha[\"Autorização\"], linha[\"NSU\"], linha[\"Chave\"], linha[\"Valor\"], status_final, round(pontuacao, 2)\n",
    "                )\n",
    "\n",
    "        return pd.Series(melhor_resultado) if melhor_resultado else pd.Series([None]*5 + [\"Não Conciliado\", 999])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro em conciliar_por_autorizacao: {str(e)}\", exc_info=True)\n",
    "        return pd.Series([None, None, None, None, \"Erro na Conciliação\", 999])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def marcar_duplicados_com_pior_score(df):\n",
    "    \"\"\"\n",
    "    Marca duplicados na coluna 'Chave ERP' com a pior pontuação (998).\n",
    "    \"\"\"\n",
    "    if \"Chave ERP\" not in df.columns:\n",
    "        return df\n",
    "    duplicados = df.duplicated(subset=[\"Chave ERP\"], keep=False)\n",
    "    df.loc[duplicados, \"Pontuação\"] = 998\n",
    "    return df\n",
    "\n",
    "def marcar_e_filtrar_chaves_utilizadas(df_erp, df_conciliado):\n",
    "    \"\"\"\n",
    "    Marca as chaves já utilizadas e retorna o ERP disponível para novas conciliações.\n",
    "    \"\"\"\n",
    "    if \"Chave ERP\" not in df_conciliado.columns or \"Chave\" not in df_erp.columns:\n",
    "        return df_erp, df_erp\n",
    "    chaves_usadas = df_conciliado[\"Chave ERP\"].dropna().unique()\n",
    "    df_erp_disponivel = df_erp[~df_erp[\"Chave\"].astype(str).isin(chaves_usadas.astype(str))]\n",
    "    return df_erp, df_erp_disponivel\n",
    "\n",
    "def gerar_relatorio_df_formatado(df_conciliado, df_nao_conciliado, df_cancelamento_venda, df_tarifas, df_aluguel):\n",
    "    \"\"\"\n",
    "    Gera um DataFrame resumo para o relatório final.\n",
    "    \"\"\"\n",
    "    resumo = {\n",
    "        \"Tipo\": [\"Conciliados\", \"Não Conciliados\", \"Cancelamentos\", \"Tarifas\", \"Aluguel\"],\n",
    "        \"Quantidade\": [\n",
    "            len(df_conciliado),\n",
    "            len(df_nao_conciliado),\n",
    "            len(df_cancelamento_venda),\n",
    "            len(df_tarifas),\n",
    "            len(df_aluguel)\n",
    "        ],\n",
    "        \"Valor Líquido\": [\n",
    "            df_conciliado[\"VALOR LÍQUIDO\"].sum() if \"VALOR LÍQUIDO\" in df_conciliado else 0,\n",
    "            df_nao_conciliado[\"VALOR LÍQUIDO\"].sum() if \"VALOR LÍQUIDO\" in df_nao_conciliado else 0,\n",
    "            df_cancelamento_venda[\"VALOR LÍQUIDO\"].sum() if \"VALOR LÍQUIDO\" in df_cancelamento_venda else 0,\n",
    "            df_tarifas[\"VALOR LÍQUIDO\"].sum() if \"VALOR LÍQUIDO\" in df_tarifas else 0,\n",
    "            df_aluguel[\"VALOR LÍQUIDO\"].sum() if \"VALOR LÍQUIDO\" in df_aluguel else 0,\n",
    "        ]\n",
    "    }\n",
    "    return pd.DataFrame(resumo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================\n",
    "# ===  INTERFACE STREAMLIT ===\n",
    "#=============================================\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # --- BARRA LATERAL ---\n",
    "        with st.sidebar:\n",
    "            st.markdown(\"# App Conciliação Bancária\")\n",
    "            st.markdown(\"### Carregar planilhas\")\n",
    "            caminho_erp = st.file_uploader(\"ERP (CSV)\", type=[\"csv\"], key=\"erp_uploader\")\n",
    "            caminho_cielo = st.file_uploader(\"Cielo (XLSX)\", type=[\"xlsx\"], key=\"cielo_uploader\")\n",
    "\n",
    "        # --- ÁREA PRINCIPAL ---\n",
    "        if caminho_erp is None or caminho_cielo is None:\n",
    "            st.subheader(\"Bem-vindo ao Sistema de Conciliação\")\n",
    "            st.markdown(\"\"\"...\"\"\")  # Mantenha seu HTML original\n",
    "            st.warning(\"⚠️ Por favor, faça upload de ambos os arquivos para iniciar a conciliação\")\n",
    "            return\n",
    "\n",
    "        # --- CARREGAMENTO DOS DADOS ---\n",
    "        try:\n",
    "            with st.spinner('📂 Carregando planilhas...'):\n",
    "                df_erp = carregar_planilha(caminho_erp)\n",
    "                df_cielo = carregar_planilha(caminho_cielo)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro ao carregar planilhas: {str(e)}\", exc_info=True)\n",
    "            st.error(f\"❌ Erro ao carregar arquivos: {str(e)}\")\n",
    "            return\n",
    "\n",
    "        # --- PROCESSAMENTO INICIAL ---\n",
    "        with st.spinner('🔧 Processando dados...'):\n",
    "            try:\n",
    "                df_cielo = limpar_cielo(df_cielo)\n",
    "                df_erp = limpar_erp(df_erp)\n",
    "\n",
    "                # Filtros iniciais\n",
    "                df_cancelamento = df_cielo[df_cielo[\"Tipo de lançamento\"] == \"Cancelamento\"].copy()\n",
    "                df_tarifas = df_cielo[df_cielo[\"Tipo de lançamento\"] == \"Tarifa\"].copy()\n",
    "                df_aluguel = df_cielo[df_cielo[\"Tipo de lançamento\"] == \"Aluguel\"].copy()\n",
    "                \n",
    "                df_cielo_principal = df_cielo[~df_cielo[\"Tipo de lançamento\"].isin(\n",
    "                    [\"Cancelamento\", \"Tarifa\", \"Pagamento Realizado\", \"Saldo Anterior\", \"Aluguel\"]\n",
    "                )].copy()\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro no processamento inicial: {str(e)}\", exc_info=True)\n",
    "                st.error(f\"❌ Erro no processamento: {str(e)}\")\n",
    "                return\n",
    "\n",
    "        # --- CONCILIAÇÃO PRINCIPAL ---\n",
    "        with st.spinner('🔁 Realizando conciliação...'):\n",
    "            try:\n",
    "                # 1ª Rodada: Conciliação por dados básicos\n",
    "                df_cielo_principal[[\"Autorização ERP\", \"NSU ERP\", \"Chave ERP\", \"Valor ERP\", \"Status\", \"Pontuação\"]] = df_cielo_principal.apply(\n",
    "                    lambda row: selecionar_melhor_por_pontuacao(row, df_erp, tolerancia_dias=1, tolerancia_valor=0.10),\n",
    "                    axis=1\n",
    "                )\n",
    "\n",
    "                # Separa conciliados e não conciliados\n",
    "                df_conciliados = df_cielo_principal[df_cielo_principal[\"Pontuação\"] != 999].copy()\n",
    "                df_nao_conciliados = df_cielo_principal[df_cielo_principal[\"Pontuação\"] == 999].copy()\n",
    "\n",
    "                # Filtra ERP disponível\n",
    "                df_erp, df_erp_disponivel = marcar_e_filtrar_chaves_utilizadas(df_erp, df_conciliados)\n",
    "\n",
    "                # 2ª Rodada: Conciliação por NSU\n",
    "                if not df_nao_conciliados.empty:\n",
    "                    df_nao_conciliados[[\"Autorização ERP\", \"NSU ERP\", \"Chave ERP\", \"Valor ERP\", \"Status\", \"Pontuação\"]] = df_nao_conciliados.apply(\n",
    "                        lambda row: conciliar_por_nsu(row, df_erp_disponivel, tolerancia_dias=5, tolerancia_valor=0.30),\n",
    "                        axis=1\n",
    "                    )\n",
    "\n",
    "                    # Atualiza listas\n",
    "                    novos_conciliados = df_nao_conciliados[df_nao_conciliados[\"Pontuação\"] != 999].copy()\n",
    "                    df_conciliados = pd.concat([df_conciliados, novos_conciliados])\n",
    "                    df_nao_conciliados = df_nao_conciliados[df_nao_conciliados[\"Pontuação\"] == 999].copy()\n",
    "\n",
    "                    # Atualiza ERP disponível\n",
    "                    df_erp, df_erp_disponivel = marcar_e_filtrar_chaves_utilizadas(df_erp, df_conciliados)\n",
    "\n",
    "                # 3ª Rodada: Conciliação por Autorização\n",
    "                if not df_nao_conciliados.empty:\n",
    "                    df_nao_conciliados[[\"Autorização ERP\", \"NSU ERP\", \"Chave ERP\", \"Valor ERP\", \"Status\", \"Pontuação\"]] = df_nao_conciliados.apply(\n",
    "                        lambda row: conciliar_por_autorizacao(row, df_erp_disponivel),\n",
    "                        axis=1\n",
    "                    )\n",
    "\n",
    "                    # Atualiza listas\n",
    "                    novos_conciliados = df_nao_conciliados[df_nao_conciliados[\"Pontuação\"] != 999].copy()\n",
    "                    df_conciliados = pd.concat([df_conciliados, novos_conciliados])\n",
    "                    df_nao_conciliados = df_nao_conciliados[df_nao_conciliados[\"Pontuação\"] == 999].copy()\n",
    "\n",
    "                # Marcar duplicados finais\n",
    "                df_conciliados = marcar_duplicados_com_pior_score(df_conciliados)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro na conciliação: {str(e)}\", exc_info=True)\n",
    "                st.error(f\"❌ Erro na conciliação: {str(e)}\")\n",
    "                return\n",
    "\n",
    "# --- RELATÓRIO FINAL ---\n",
    "        # --- RELATÓRIO FINAL ---\n",
    "        with st.spinner('📊 Gerando relatórios...'):\n",
    "\n",
    "            # === DEBUG: mostrar dtypes das colunas financeiras antes de formatar ===\n",
    "            cols_formatar = [\n",
    "                \"VALOR DA PARCELA\",\n",
    "                \"VALOR LÍQUIDO\",\n",
    "                \"valor total da transação\",\n",
    "                \"taxa/tarifa\",\n",
    "                \"Valor ERP\"\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                # Cálculo dos totais\n",
    "                total_conciliado = df_conciliados[\"VALOR LÍQUIDO\"].sum()\n",
    "                total_nao_conciliado = (\n",
    "                    df_nao_conciliados[\"VALOR LÍQUIDO\"].sum()\n",
    "                    if not df_nao_conciliados.empty else 0\n",
    "                )\n",
    "                total_cancelamentos = df_cancelamento[\"VALOR LÍQUIDO\"].sum()\n",
    "\n",
    "                # Exibição dos resultados\n",
    "                st.header(\"Resultados da Conciliação\")\n",
    "                col1, col2, col3 = st.columns(3)\n",
    "                col1.metric(\"✅ Conciliados\", f\"R$ {total_conciliado:,.2f}\", f\"{len(df_conciliados)} registros\")\n",
    "                col2.metric(\"⚠ Não Conciliados\", f\"R$ {total_nao_conciliado:,.2f}\", f\"{len(df_nao_conciliados)} registros\")\n",
    "                col3.metric(\"❌ Cancelamentos\", f\"R$ {total_cancelamentos:,.2f}\", f\"{len(df_cancelamento)} registros\")\n",
    "\n",
    "                # Geração do Excel com formatação brasileira\n",
    "                output = io.BytesIO()\n",
    "                with pd.ExcelWriter(output, engine='openpyxl') as writer:\n",
    "\n",
    "                    def formatar(df):\n",
    "                        for col in cols_formatar:\n",
    "                            if col in df.columns:\n",
    "                                # garante que é float antes de formatar\n",
    "                                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                                df[col] = df[col].apply(\n",
    "                                    lambda x: f\"{x:.2f}\".replace('.', ',') if pd.notnull(x) else \"\"\n",
    "                                )\n",
    "                        return df\n",
    "\n",
    "                    formatar(df_conciliados).to_excel(writer, sheet_name='Conciliados', index=False)\n",
    "                    formatar(df_nao_conciliados).to_excel(writer, sheet_name='Não Conciliados', index=False)\n",
    "                    formatar(df_cancelamento).to_excel(writer, sheet_name='Cancelamentos', index=False)\n",
    "                    formatar(df_tarifas).to_excel(writer, sheet_name='Tarifas', index=False)\n",
    "                    formatar(df_aluguel).to_excel(writer, sheet_name='Aluguel', index=False)\n",
    "\n",
    "                st.download_button(\n",
    "                    label=\"📥 Baixar Relatório Completo\",\n",
    "                    data=output.getvalue(),\n",
    "                    file_name=\"Relatorio_Conciliação_Cielo.xlsx\",\n",
    "                    mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao gerar relatório: {str(e)}\", exc_info=True)\n",
    "                st.error(f\"❌ Erro ao gerar relatório: {str(e)}\")\n",
    "\n",
    "                return\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro inesperado: {str(e)}\", exc_info=True)\n",
    "        st.error(f\"❌ Erro crítico: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
